{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cfd818a",
   "metadata": {},
   "source": [
    "# GenD: Generalized Deepfake Detection — Self-Contained Training Notebook\n",
    "\n",
    "## Cách sử dụng trên Kaggle:\n",
    "1. **Upload dataset** (ảnh frames đã crop mặt) lên Kaggle Dataset\n",
    "2. **Upload file JSON** mô tả dataset (xem hướng dẫn ở cell Config)\n",
    "3. **Bật GPU** (Settings > Accelerator > GPU T4 x2)\n",
    "4. **Bật Internet** (Settings > Internet > On) — cần lần đầu để tải CLIP weights\n",
    "5. **Chạy tất cả cell** từ trên xuống dưới\n",
    "6. Model sẽ được lưu tại `/kaggle/working/gend_checkpoints/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a8f37",
   "metadata": {},
   "source": [
    "## Cell 1 — Cài đặt thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a771c9bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T02:55:58.098019Z",
     "iopub.status.busy": "2026-02-07T02:55:58.097725Z",
     "iopub.status.idle": "2026-02-07T02:56:01.317132Z",
     "shell.execute_reply": "2026-02-07T02:56:01.316169Z",
     "shell.execute_reply.started": "2026-02-07T02:55:58.097994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q albumentations transformers lmdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058fb8df",
   "metadata": {},
   "source": [
    "## Cell 2 — Import toàn bộ thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa9d6322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T02:56:01.319342Z",
     "iopub.status.busy": "2026-02-07T02:56:01.319022Z",
     "iopub.status.idle": "2026-02-07T02:56:01.326904Z",
     "shell.execute_reply": "2026-02-07T02:56:01.326125Z",
     "shell.execute_reply.started": "2026-02-07T02:56:01.319314Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.8.0+cu126\n",
      "CUDA available: True\n",
      "GPU: Tesla T4\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import datetime\n",
    "import logging\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations import DualTransform, ImageOnlyTransform\n",
    "\n",
    "from sklearn import metrics as sk_metrics\n",
    "\n",
    "from transformers import CLIPModel\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0db3b4",
   "metadata": {},
   "source": [
    "## Cell 3 — Cấu hình (Thay thế file YAML)\n",
    "\n",
    "### Hướng dẫn:\n",
    "- **`dataset_json_folder`**: Thư mục chứa file JSON mô tả dataset.  \n",
    "  Trên Kaggle: upload file JSON vào một Kaggle Dataset, rồi trỏ đường dẫn tới đó.\n",
    "- **`rgb_dir`**: Thư mục gốc chứa ảnh frames (nếu đường dẫn trong JSON là tương đối).\n",
    "- **`train_dataset`**: List tên dataset đúng với key trong file JSON.\n",
    "- **`test_dataset`**: List tên dataset dùng để test.\n",
    "\n",
    "### Cấu trúc file JSON mẫu (`MyDataset.json`):\n",
    "```json\n",
    "{\n",
    "  \"MyDataset\": {\n",
    "    \"real\": {\n",
    "      \"train\": {\n",
    "        \"video_001\": {\n",
    "          \"label\": \"FF-real\",\n",
    "          \"frames\": [\"/kaggle/input/mydata/real/001/0.png\", ...]\n",
    "        }\n",
    "      },\n",
    "      \"test\": { ... }\n",
    "    },\n",
    "    \"fake\": {\n",
    "      \"train\": {\n",
    "        \"video_002\": {\n",
    "          \"label\": \"FF-DF\",\n",
    "          \"frames\": [\"/kaggle/input/mydata/fake/002/0.png\", ...]\n",
    "        }\n",
    "      },\n",
    "      \"test\": { ... }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Label phải khớp với key trong `label_dict` bên dưới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2d18087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T03:00:44.655982Z",
     "iopub.status.busy": "2026-02-07T03:00:44.655690Z",
     "iopub.status.idle": "2026-02-07T03:00:44.666750Z",
     "shell.execute_reply": "2026-02-07T03:00:44.666090Z",
     "shell.execute_reply.started": "2026-02-07T03:00:44.655954Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Config loaded.\n",
      "   Train dataset: ['FaceForensics++']\n",
      "   Test dataset:  ['Celeb-DF-v2']\n",
      "   Epochs:        10\n",
      "   Batch size:    16\n",
      "   Resolution:    224\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\n",
    "    'dataset_json_folder': '/kaggle/input/deepfakebench/dataset_json',   # <-- Folder chứa file .json\n",
    "    'rgb_dir':             '/kaggle/input/deepfakebench/data',  # <-- Folder gốc chứa ảnh\n",
    "    'train_dataset':       ['FaceForensics++'],                  # <-- Tên dataset (key trong JSON)\n",
    "    'test_dataset':        ['Celeb-DF-v2'],                      # <-- Tên dataset test\n",
    "\n",
    "    # Model \n",
    "    'model_name':    'gend',\n",
    "    'backbone_name': 'vit',\n",
    "    'lambda_align':  1.0,    # Hệ số Alignment Loss\n",
    "    'lambda_unif':   1.0,    # Hệ số Uniformity Loss\n",
    "\n",
    "    # ---- Dataset ----\n",
    "    'compression':    'c23',\n",
    "    'train_batchSize': 16,   # Giảm xuống nếu hết VRAM (Kaggle T4 = 16GB)\n",
    "    'test_batchSize':  16,\n",
    "    'workers':         2,    # Kaggle thường 2-4\n",
    "    'frame_num':       {'train': 8, 'test': 32},\n",
    "    'resolution':      224,\n",
    "    'with_mask':       False,\n",
    "    'with_landmark':   False,\n",
    "    'lmdb':            False,\n",
    "\n",
    "    # ---- Data Augmentation ----\n",
    "    'use_data_augmentation': True,\n",
    "    'data_aug': {\n",
    "        'flip_prob':       0.5,\n",
    "        'rotate_prob':     0.5,\n",
    "        'rotate_limit':    [-10, 10],\n",
    "        'blur_prob':       0.5,\n",
    "        'blur_limit':      [3, 7],\n",
    "        'brightness_prob': 0.5,\n",
    "        'brightness_limit':[-0.1, 0.1],\n",
    "        'contrast_limit':  [-0.1, 0.1],\n",
    "        'quality_lower':   40,\n",
    "        'quality_upper':   100,\n",
    "    },\n",
    "\n",
    "    # ---- Normalization (CLIP) ----\n",
    "    'mean': [0.48145466, 0.4578275, 0.40821073],\n",
    "    'std':  [0.26862954, 0.26130258, 0.27577711],\n",
    "\n",
    "    # ---- Optimizer ----\n",
    "    'optimizer': {\n",
    "        'type': 'adam',\n",
    "        'adam': {\n",
    "            'lr':           0.0002,\n",
    "            'beta1':        0.9,\n",
    "            'beta2':        0.999,\n",
    "            'eps':          1e-8,\n",
    "            'weight_decay': 0.0005,\n",
    "            'amsgrad':      False,\n",
    "        },\n",
    "        'sgd': {\n",
    "            'lr':           0.0002,\n",
    "            'momentum':     0.9,\n",
    "            'weight_decay': 0.0005,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # ---- Training ----\n",
    "    'lr_scheduler': None,   # None, 'step', 'cosine', 'linear'\n",
    "    'nEpochs':      10,\n",
    "    'start_epoch':  0,\n",
    "    'save_epoch':   1,\n",
    "    'rec_iter':     100,    # In log mỗi bao nhiêu iteration\n",
    "    'manualSeed':   1024,\n",
    "    'save_ckpt':    True,\n",
    "    'save_feat':    True,\n",
    "\n",
    "    # ---- Loss ----\n",
    "    'loss_func':    'cross_entropy',\n",
    "\n",
    "    # ---- Metric ----\n",
    "    'metric_scoring': 'auc',\n",
    "\n",
    "    # ---- CUDA ----\n",
    "    'cuda': True,\n",
    "\n",
    "    # ---- Output ----\n",
    "    'log_dir': '/kaggle/working/gend_checkpoints',\n",
    "\n",
    "    # ---- Label Mapping ----\n",
    "    # Tên label trong JSON -> số (0=real, 1=fake)\n",
    "    'label_dict': {\n",
    "        # FF++ & FaceShifter\n",
    "        'FF-real': 0, 'FF-DF': 1, 'FF-F2F': 1, 'FF-FS': 1, 'FF-NT': 1, 'FF-FH': 1, 'FF-SH': 1,\n",
    "        # DFD\n",
    "        'DFD_fake': 1, 'DFD_real': 0,\n",
    "        # CelebDF\n",
    "        'CelebDFv1_real': 0, 'CelebDFv1_fake': 1,\n",
    "        'CelebDFv2_real': 0, 'CelebDFv2_fake': 1,\n",
    "        # DFDCP\n",
    "        'DFDCP_Real': 0, 'DFDCP_FakeA': 1, 'DFDCP_FakeB': 1,\n",
    "        # DFDC\n",
    "        'DFDC_Fake': 1, 'DFDC_Real': 0,\n",
    "        # DeeperForensics\n",
    "        'DF_fake': 1, 'DF_real': 0,\n",
    "        # UADFV\n",
    "        'UADFV_Fake': 1, 'UADFV_Real': 0,\n",
    "        # Roop\n",
    "        'roop_Real': 0, 'roop_Fake': 1,\n",
    "    },\n",
    "}\n",
    "\n",
    "os.makedirs(config['log_dir'], exist_ok=True)\n",
    "print(\"\\u2705 Config loaded.\")\n",
    "print(f\"   Train dataset: {config['train_dataset']}\")\n",
    "print(f\"   Test dataset:  {config['test_dataset']}\")\n",
    "print(f\"   Epochs:        {config['nEpochs']}\")\n",
    "print(f\"   Batch size:    {config['train_batchSize']}\")\n",
    "print(f\"   Resolution:    {config['resolution']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f51d10",
   "metadata": {},
   "source": [
    "## Cell 4 — Seed & Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f80452a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T02:56:01.343547Z",
     "iopub.status.busy": "2026-02-07T02:56:01.343319Z",
     "iopub.status.idle": "2026-02-07T02:56:01.358207Z",
     "shell.execute_reply": "2026-02-07T02:56:01.357546Z",
     "shell.execute_reply.started": "2026-02-07T02:56:01.343509Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Seed set to 1024\n",
      "[02:56:01] Log directory: /kaggle/working/gend_checkpoints/gend_2026-02-07-02-56-01\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  Seed để tái lập kết quả\n",
    "# ============================================================\n",
    "def init_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "init_seed(config['manualSeed'])\n",
    "print(f\"\\u2705 Seed set to {config['manualSeed']}\")\n",
    "\n",
    "# ============================================================\n",
    "#  Simple Logger (thay thế logger.py gốc)\n",
    "# ============================================================\n",
    "class NotebookLogger:\n",
    "    \"\"\"Logger đơn giản in ra notebook + ghi file.\"\"\"\n",
    "    def __init__(self, log_path=None):\n",
    "        self.log_path = log_path\n",
    "        if log_path:\n",
    "            os.makedirs(os.path.dirname(log_path), exist_ok=True)\n",
    "            self.file = open(log_path, 'a')\n",
    "        else:\n",
    "            self.file = None\n",
    "\n",
    "    def info(self, msg):\n",
    "        timestamp = datetime.datetime.now().strftime('%H:%M:%S')\n",
    "        line = f\"[{timestamp}] {msg}\"\n",
    "        print(line)\n",
    "        if self.file:\n",
    "            self.file.write(line + '\\n')\n",
    "            self.file.flush()\n",
    "\n",
    "    def warning(self, msg):\n",
    "        self.info(f\"\\u26a0\\ufe0f {msg}\")\n",
    "\n",
    "    def error(self, msg):\n",
    "        self.info(f\"\\u274c {msg}\")\n",
    "\n",
    "timenow = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "log_dir = os.path.join(config['log_dir'], f\"{config['model_name']}_{timenow}\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "logger = NotebookLogger(os.path.join(log_dir, 'training.log'))\n",
    "logger.info(f\"Log directory: {log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96995e6",
   "metadata": {},
   "source": [
    "## Cell 5 — Augmentation Helpers\n",
    "\n",
    "Sao chép từ `training/dataset/albu.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce5ba5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T02:56:01.373472Z",
     "iopub.status.busy": "2026-02-07T02:56:01.373234Z",
     "iopub.status.idle": "2026-02-07T02:56:01.385960Z",
     "shell.execute_reply": "2026-02-07T02:56:01.385351Z",
     "shell.execute_reply.started": "2026-02-07T02:56:01.373452Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Augmentation helpers loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  Nguồn: training/dataset/albu.py\n",
    "# ============================================================\n",
    "\n",
    "def isotropically_resize_image(img, size, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC):\n",
    "    h, w = img.shape[:2]\n",
    "    if max(w, h) == size:\n",
    "        return img\n",
    "    if w > h:\n",
    "        scale = size / w\n",
    "        h = h * scale\n",
    "        w = size\n",
    "    else:\n",
    "        scale = size / h\n",
    "        w = w * scale\n",
    "        h = size\n",
    "    interpolation = interpolation_up if scale > 1 else interpolation_down\n",
    "    resized = cv2.resize(img, (int(w), int(h)), interpolation=interpolation)\n",
    "    return resized\n",
    "\n",
    "\n",
    "class IsotropicResize(DualTransform):\n",
    "    def __init__(self, max_side, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC,\n",
    "                 always_apply=False, p=1):\n",
    "        # FIX: Use kwargs explicitly (Albumentations updated __init__ signature order in newer versions)\n",
    "        super(IsotropicResize, self).__init__(p=p, always_apply=always_apply)\n",
    "        self.max_side = max_side\n",
    "        self.interpolation_down = interpolation_down\n",
    "        self.interpolation_up = interpolation_up\n",
    "\n",
    "    def apply(self, img, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC, **params):\n",
    "        return isotropically_resize_image(img, size=self.max_side, interpolation_down=interpolation_down,\n",
    "                                          interpolation_up=interpolation_up)\n",
    "\n",
    "    def apply_to_mask(self, img, **params):\n",
    "        return self.apply(img, interpolation_down=cv2.INTER_NEAREST, interpolation_up=cv2.INTER_NEAREST, **params)\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return (\"max_side\", \"interpolation_down\", \"interpolation_up\")\n",
    "\n",
    "\n",
    "print(\"\\u2705 Augmentation helpers loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c44867",
   "metadata": {},
   "source": [
    "## Cell 6 — Dataset Class\n",
    "\n",
    "Sao chép từ `training/dataset/abstract_dataset.py`.  \n",
    "- Đã bỏ `from .albu import IsotropicResize` (dùng class ở cell trên).  \n",
    "- Đã bỏ LMDB-related code cho gọn (giữ `lmdb=False` trong config)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92b37a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T02:56:01.387024Z",
     "iopub.status.busy": "2026-02-07T02:56:01.386808Z",
     "iopub.status.idle": "2026-02-07T02:56:01.412239Z",
     "shell.execute_reply": "2026-02-07T02:56:01.411529Z",
     "shell.execute_reply.started": "2026-02-07T02:56:01.387003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset class loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  Nguồn: training/dataset/abstract_dataset.py\n",
    "#  Đã chỉnh sửa: bỏ relative import, bỏ LMDB, inline IsotropicResize\n",
    "#  FIX: __getitem__ trả về 4 giá trị, collate_fn khớp với project gốc\n",
    "# ============================================================\n",
    "\n",
    "FFpp_pool = ['FaceForensics++', 'FaceShifter', 'DeepFakeDetection', 'FF-DF', 'FF-F2F', 'FF-FS', 'FF-NT']\n",
    "\n",
    "\n",
    "class DeepfakeAbstractBaseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class dùng cho training GenD.\n",
    "    Đọc ảnh từ danh sách frame trong file JSON.\n",
    "    \"\"\"\n",
    "    def __init__(self, config=None, mode='train'):\n",
    "        self.config = config\n",
    "        self.mode = mode\n",
    "        self.compression = config['compression']\n",
    "        self.frame_num = config['frame_num'][mode]\n",
    "        self.image_list = []\n",
    "        self.label_list = []\n",
    "\n",
    "        if mode == 'train':\n",
    "            dataset_list = config['train_dataset']\n",
    "            image_list, label_list = [], []\n",
    "            for one_data in dataset_list:\n",
    "                tmp_image, tmp_label, tmp_name = self.collect_img_and_label_for_one_dataset(one_data)\n",
    "                image_list.extend(tmp_image)\n",
    "                label_list.extend(tmp_label)\n",
    "        elif mode == 'test':\n",
    "            one_data = config['test_dataset']\n",
    "            image_list, label_list, _ = self.collect_img_and_label_for_one_dataset(one_data)\n",
    "        else:\n",
    "            raise NotImplementedError('Only train and test modes are supported.')\n",
    "\n",
    "        assert len(image_list) != 0, f\"Collect nothing for {mode} mode!\"\n",
    "        self.image_list, self.label_list = image_list, label_list\n",
    "\n",
    "        self.data_dict = {\n",
    "            'image': self.image_list,\n",
    "            'label': self.label_list,\n",
    "        }\n",
    "\n",
    "        self.transform = self.init_data_aug_method()\n",
    "\n",
    "    def init_data_aug_method(self):\n",
    "        trans = A.Compose([\n",
    "            A.HorizontalFlip(p=self.config['data_aug']['flip_prob']),\n",
    "            A.Rotate(limit=self.config['data_aug']['rotate_limit'], p=self.config['data_aug']['rotate_prob']),\n",
    "            A.GaussianBlur(blur_limit=self.config['data_aug']['blur_limit'], p=self.config['data_aug']['blur_prob']),\n",
    "            A.OneOf([\n",
    "                IsotropicResize(max_side=self.config['resolution'], interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC),\n",
    "                IsotropicResize(max_side=self.config['resolution'], interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_LINEAR),\n",
    "                IsotropicResize(max_side=self.config['resolution'], interpolation_down=cv2.INTER_LINEAR, interpolation_up=cv2.INTER_LINEAR),\n",
    "            ], p=1),\n",
    "            A.OneOf([\n",
    "                A.RandomBrightnessContrast(\n",
    "                    brightness_limit=self.config['data_aug']['brightness_limit'],\n",
    "                    contrast_limit=self.config['data_aug']['contrast_limit']),\n",
    "                A.FancyPCA(),\n",
    "                A.HueSaturationValue()\n",
    "            ], p=0.5),\n",
    "            A.ImageCompression(\n",
    "                quality_lower=self.config['data_aug']['quality_lower'],\n",
    "                quality_upper=self.config['data_aug']['quality_upper'], p=0.5),\n",
    "        ])\n",
    "        return trans\n",
    "\n",
    "    def collect_img_and_label_for_one_dataset(self, dataset_name: str):\n",
    "        label_list = []\n",
    "        frame_path_list = []\n",
    "        video_name_list = []\n",
    "\n",
    "        json_path = os.path.join(self.config['dataset_json_folder'], dataset_name + '.json')\n",
    "        try:\n",
    "            with open(json_path, 'r') as f:\n",
    "                dataset_info = json.load(f)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f'Dataset JSON not found: {json_path}. Error: {e}')\n",
    "\n",
    "        # Xử lý _c40 variant (giống gốc)\n",
    "        cp = None\n",
    "        original_name = dataset_name\n",
    "        if dataset_name == 'FaceForensics++_c40':\n",
    "            original_name = 'FaceForensics++'; cp = 'c40'\n",
    "        elif dataset_name == 'FF-DF_c40':\n",
    "            original_name = 'FF-DF'; cp = 'c40'\n",
    "        elif dataset_name == 'FF-F2F_c40':\n",
    "            original_name = 'FF-F2F'; cp = 'c40'\n",
    "        elif dataset_name == 'FF-FS_c40':\n",
    "            original_name = 'FF-FS'; cp = 'c40'\n",
    "        elif dataset_name == 'FF-NT_c40':\n",
    "            original_name = 'FF-NT'; cp = 'c40'\n",
    "\n",
    "        for label_key in dataset_info[original_name]:\n",
    "            sub_dataset_info = dataset_info[original_name][label_key][self.mode]\n",
    "\n",
    "            # Xử lý compression cho FF++ family (giống gốc)\n",
    "            ff_family = ['FF-DF', 'FF-F2F', 'FF-FS', 'FF-NT', 'FaceForensics++', 'DeepFakeDetection', 'FaceShifter']\n",
    "            if cp is None and original_name in ff_family:\n",
    "                sub_dataset_info = sub_dataset_info[self.compression]\n",
    "            elif cp == 'c40' and original_name in ff_family:\n",
    "                sub_dataset_info = sub_dataset_info['c40']\n",
    "\n",
    "            for video_name, video_info in sub_dataset_info.items():\n",
    "                unique_video_name = video_info['label'] + '_' + video_name\n",
    "\n",
    "                if video_info['label'] not in self.config['label_dict']:\n",
    "                    raise ValueError(f\"Label '{video_info['label']}' not found in config['label_dict'].\")\n",
    "                label = self.config['label_dict'][video_info['label']]\n",
    "                frame_paths = video_info['frames']\n",
    "\n",
    "                # Sắp xếp frame theo số (giống gốc)\n",
    "                if len(frame_paths) > 0:\n",
    "                    if '\\\\' in frame_paths[0]:\n",
    "                        frame_paths = sorted(frame_paths, key=lambda x: int(x.split('\\\\')[-1].split('.')[0]))\n",
    "                    else:\n",
    "                        frame_paths = sorted(frame_paths, key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "\n",
    "                # Lấy số frame cần thiết (giống gốc)\n",
    "                total_frames = len(frame_paths)\n",
    "                if self.frame_num < total_frames:\n",
    "                    total_frames = self.frame_num\n",
    "                    step = total_frames // self.frame_num\n",
    "                    frame_paths = [frame_paths[i] for i in range(0, total_frames, step)][:self.frame_num]\n",
    "\n",
    "                label_list.extend([label] * total_frames)\n",
    "                frame_path_list.extend(frame_paths)\n",
    "                video_name_list.extend([unique_video_name] * total_frames)\n",
    "\n",
    "        # Shuffle\n",
    "        combined = list(zip(label_list, frame_path_list, video_name_list))\n",
    "        random.shuffle(combined)\n",
    "        label_list, frame_path_list, video_name_list = zip(*combined) if combined else ([], [], [])\n",
    "\n",
    "        return list(frame_path_list), list(label_list), list(video_name_list)\n",
    "\n",
    "    def load_rgb(self, file_path):\n",
    "        size = self.config['resolution']\n",
    "        # Nếu đường dẫn tương đối, gắn với rgb_dir (giống gốc)\n",
    "        if not file_path.startswith('/'):\n",
    "            if file_path.startswith('./'):\n",
    "                file_path = file_path[2:]\n",
    "            file_path = os.path.join(self.config['rgb_dir'], file_path)\n",
    "\n",
    "        file_path = file_path.replace('\\\\', '/')\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            raise ValueError(f\"File not found: {file_path}\")\n",
    "\n",
    "        img = cv2.imread(file_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f'Loaded image is None: {file_path}')\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (size, size), interpolation=cv2.INTER_CUBIC)\n",
    "        return Image.fromarray(np.array(img, dtype=np.uint8))\n",
    "\n",
    "    def to_tensor(self, img):\n",
    "        return T.ToTensor()(img)\n",
    "\n",
    "    def normalize(self, img):\n",
    "        mean = self.config['mean']\n",
    "        std = self.config['std']\n",
    "        return T.Normalize(mean=mean, std=std)(img)\n",
    "\n",
    "    def data_aug(self, img, landmark=None, mask=None, augmentation_seed=None):\n",
    "        \"\"\"Augmentation — giống gốc abstract_dataset.py (landmark/mask=None cho GenD).\"\"\"\n",
    "        if augmentation_seed is not None:\n",
    "            random.seed(augmentation_seed)\n",
    "            np.random.seed(augmentation_seed)\n",
    "\n",
    "        kwargs = {'image': img}\n",
    "        # GenD không dùng landmark/mask, nhưng giữ interface cho tương thích\n",
    "        if landmark is not None:\n",
    "            kwargs['keypoints'] = landmark\n",
    "            kwargs['keypoint_params'] = A.KeypointParams(format='xy')\n",
    "        if mask is not None:\n",
    "            mask_sq = mask.squeeze(2)\n",
    "            if mask_sq.max() > 0:\n",
    "                kwargs['mask'] = mask_sq\n",
    "\n",
    "        transformed = self.transform(**kwargs)\n",
    "        augmented_img = transformed['image']\n",
    "        augmented_landmark = transformed.get('keypoints')\n",
    "        augmented_mask = transformed.get('mask', mask)\n",
    "\n",
    "        if augmented_landmark is not None:\n",
    "            augmented_landmark = np.array(augmented_landmark)\n",
    "        if augmentation_seed is not None:\n",
    "            random.seed()\n",
    "            np.random.seed()\n",
    "\n",
    "        return augmented_img, augmented_landmark, augmented_mask\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Trả về 4 giá trị (image, label, landmark, mask) — giống gốc.\"\"\"\n",
    "        image_path = self.data_dict['image'][index]\n",
    "        label = self.data_dict['label'][index]\n",
    "\n",
    "        try:\n",
    "            image = self.load_rgb(image_path)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to load index {index}: {e}\")\n",
    "            if index == 0:\n",
    "                raise e\n",
    "            return self.__getitem__(0)\n",
    "\n",
    "        image = np.array(image)\n",
    "        mask = None\n",
    "        landmarks = None\n",
    "\n",
    "        # Augmentation (chỉ khi train) — giống gốc\n",
    "        if self.mode == 'train' and self.config['use_data_augmentation']:\n",
    "            image_trans, landmarks_trans, mask_trans = self.data_aug(image, landmarks, mask)\n",
    "        else:\n",
    "            image_trans = deepcopy(image)\n",
    "            landmarks_trans = deepcopy(landmarks)\n",
    "            mask_trans = deepcopy(mask)\n",
    "\n",
    "        # To tensor & normalize\n",
    "        image_trans = self.normalize(self.to_tensor(image_trans))\n",
    "\n",
    "        return image_trans, label, landmarks_trans, mask_trans\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        \"\"\"Collate — giống gốc abstract_dataset.py (unpack 4 giá trị).\"\"\"\n",
    "        images, labels, landmarks, masks = zip(*batch)\n",
    "        images = torch.stack(images, dim=0)\n",
    "        labels = torch.LongTensor(labels)\n",
    "\n",
    "        if not any(landmark is None or (isinstance(landmark, list) and None in landmark) for landmark in landmarks):\n",
    "            landmarks = torch.stack(landmarks, dim=0)\n",
    "        else:\n",
    "            landmarks = None\n",
    "\n",
    "        if not any(m is None or (isinstance(m, list) and None in m) for m in masks):\n",
    "            masks = torch.stack(masks, dim=0)\n",
    "        else:\n",
    "            masks = None\n",
    "\n",
    "        data_dict = {\n",
    "            'image': images,\n",
    "            'label': labels,\n",
    "            'landmark': landmarks,\n",
    "            'mask': masks,\n",
    "        }\n",
    "        return data_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "\n",
    "print(\"\\u2705 Dataset class loaded (matching original project).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677b7d5c",
   "metadata": {},
   "source": [
    "## Cell 7 — Metrics\n",
    "\n",
    "Sao chép từ `training/metrics/base_metrics_class.py` và `training/metrics/utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad64ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T02:56:01.413618Z",
     "iopub.status.busy": "2026-02-07T02:56:01.413177Z",
     "iopub.status.idle": "2026-02-07T02:56:01.429623Z",
     "shell.execute_reply": "2026-02-07T02:56:01.429122Z",
     "shell.execute_reply.started": "2026-02-07T02:56:01.413595Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metrics loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  Nguồn: training/metrics/base_metrics_class.py + training/metrics/utils.py\n",
    "#  FIX: Recorder dùng sum/num (giống gốc), calculate_metrics_for_train dùng .squeeze(),\n",
    "#       get_test_metrics dùng get_video_metrics gốc, thêm parse_metric_for_print\n",
    "# ============================================================\n",
    "\n",
    "class Recorder:\n",
    "    \"\"\"Recorder giống hệt project gốc (sum/num thay vì list).\"\"\"\n",
    "    def __init__(self):\n",
    "        self.sum = 0\n",
    "        self.num = 0\n",
    "\n",
    "    def update(self, item, num=1):\n",
    "        if item is not None:\n",
    "            if isinstance(item, torch.Tensor):\n",
    "                item = item.item()\n",
    "            self.sum += item * num\n",
    "            self.num += num\n",
    "\n",
    "    def average(self):\n",
    "        if self.num == 0:\n",
    "            return None\n",
    "        return self.sum / self.num\n",
    "\n",
    "    def clear(self):\n",
    "        self.sum = 0\n",
    "        self.num = 0\n",
    "\n",
    "\n",
    "def calculate_metrics_for_train(label, output):\n",
    "    \"\"\"Tính AUC, EER, ACC, AP — khớp hệt file gốc base_metrics_class.py.\"\"\"\n",
    "    if output.size(1) == 2:\n",
    "        prob = torch.softmax(output, dim=1)[:, 1]\n",
    "    else:\n",
    "        prob = output\n",
    "\n",
    "    # Accuracy\n",
    "    _, prediction = torch.max(output, 1)\n",
    "    correct = (prediction == label).sum().item()\n",
    "    accuracy = correct / prediction.size(0)\n",
    "\n",
    "    # Average Precision\n",
    "    y_true = label.cpu().detach().numpy()\n",
    "    y_pred = prob.cpu().detach().numpy()\n",
    "    ap = sk_metrics.average_precision_score(y_true, y_pred)\n",
    "\n",
    "    # AUC and EER (giống gốc: dùng .squeeze())\n",
    "    try:\n",
    "        fpr, tpr, thresholds = sk_metrics.roc_curve(\n",
    "            label.squeeze().cpu().numpy(),\n",
    "            prob.squeeze().cpu().numpy(),\n",
    "            pos_label=1\n",
    "        )\n",
    "    except:\n",
    "        # for the case when we only have one sample\n",
    "        return None, None, accuracy, ap\n",
    "\n",
    "    if np.isnan(fpr[0]) or np.isnan(tpr[0]):\n",
    "        # for the case when all the samples within a batch is fake/real\n",
    "        auc, eer = None, None\n",
    "    else:\n",
    "        auc = sk_metrics.auc(fpr, tpr)\n",
    "        fnr = 1 - tpr\n",
    "        eer = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "\n",
    "    return auc, eer, accuracy, ap\n",
    "\n",
    "\n",
    "def get_test_metrics(y_pred, y_true, img_names):\n",
    "    \"\"\"Tính metric toàn cục — khớp hệt file gốc metrics/utils.py (bao gồm video-level AUC).\"\"\"\n",
    "\n",
    "    def get_video_metrics(image, pred, label):\n",
    "        \"\"\"Video-level AUC — khớp hệt hàm gốc trong metrics/utils.py.\"\"\"\n",
    "        result_dict = {}\n",
    "        new_label = []\n",
    "        new_pred = []\n",
    "\n",
    "        for item in np.transpose(np.stack((image, pred, label)), (1, 0)):\n",
    "            s = item[0]\n",
    "            if '\\\\' in s:\n",
    "                parts = s.split('\\\\')\n",
    "            else:\n",
    "                parts = s.split('/')\n",
    "            a = parts[-2]  # tên video folder (parent directory)\n",
    "\n",
    "            if a not in result_dict:\n",
    "                result_dict[a] = []\n",
    "            result_dict[a].append(item)\n",
    "\n",
    "        image_arr = list(result_dict.values())\n",
    "        for video in image_arr:\n",
    "            pred_sum = 0\n",
    "            label_sum = 0\n",
    "            leng = 0\n",
    "            for frame in video:\n",
    "                pred_sum += float(frame[1])\n",
    "                label_sum += int(frame[2])\n",
    "                leng += 1\n",
    "            new_pred.append(pred_sum / leng)\n",
    "            new_label.append(int(label_sum / leng))\n",
    "\n",
    "        fpr, tpr, thresholds = sk_metrics.roc_curve(new_label, new_pred)\n",
    "        v_auc = sk_metrics.auc(fpr, tpr)\n",
    "        fnr = 1 - tpr\n",
    "        v_eer = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "        return v_auc, v_eer\n",
    "\n",
    "    y_pred = y_pred.squeeze()\n",
    "    # For UCF, where labels for different manipulations are not consistent.\n",
    "    y_true[y_true >= 1] = 1\n",
    "\n",
    "    # AUC\n",
    "    fpr, tpr, thresholds = sk_metrics.roc_curve(y_true, y_pred, pos_label=1)\n",
    "    auc = sk_metrics.auc(fpr, tpr)\n",
    "    # EER\n",
    "    fnr = 1 - tpr\n",
    "    eer = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "    # AP\n",
    "    ap = sk_metrics.average_precision_score(y_true, y_pred)\n",
    "    # ACC\n",
    "    prediction_class = (y_pred > 0.5).astype(int)\n",
    "    correct = (prediction_class == np.clip(y_true, a_min=0, a_max=1)).sum().item()\n",
    "    acc = correct / len(prediction_class)\n",
    "\n",
    "    # Video-level AUC (giống gốc: dùng get_video_metrics)\n",
    "    if type(img_names[0]) is not list:\n",
    "        # frame-level methods -> tính video-level AUC\n",
    "        v_auc, _ = get_video_metrics(img_names, y_pred, y_true)\n",
    "    else:\n",
    "        # video-level methods\n",
    "        v_auc = auc\n",
    "\n",
    "    return {'acc': acc, 'auc': auc, 'eer': eer, 'ap': ap, 'pred': y_pred, 'video_auc': v_auc, 'label': y_true}\n",
    "\n",
    "\n",
    "def parse_metric_for_print(metric_dict):\n",
    "    \"\"\"Format best metrics để in log — giống hệt file gốc metrics/utils.py.\"\"\"\n",
    "    if metric_dict is None:\n",
    "        return \"\\n\"\n",
    "    s = \"\\n\"\n",
    "    s += \"================================ Each dataset best metric ================================ \\n\"\n",
    "    for key, value in metric_dict.items():\n",
    "        if key != 'avg':\n",
    "            s += f\"| {key}: \"\n",
    "            for k, v in value.items():\n",
    "                s += f\" {k}={v} \"\n",
    "            s += \"| \\n\"\n",
    "        else:\n",
    "            s += \"============================================================================================= \\n\"\n",
    "            s += \"================================== Average best metric ====================================== \\n\"\n",
    "            avg_dict = value\n",
    "            for avg_key, avg_value in avg_dict.items():\n",
    "                if avg_key == 'dataset_dict':\n",
    "                    for dk, dv in avg_value.items():\n",
    "                        s += f\"| {dk}: {dv} | \\n\"\n",
    "                else:\n",
    "                    s += f\"| avg {avg_key}: {avg_value} | \\n\"\n",
    "    s += \"=============================================================================================\"\n",
    "    return s\n",
    "\n",
    "\n",
    "print(\"\\u2705 Metrics loaded (matching original project).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8317d75",
   "metadata": {},
   "source": [
    "## Cell 8 — Loss Functions (Alignment & Uniformity)\n",
    "\n",
    "Sao chép từ `training/detectors/gend_detector.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f56ad1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T02:56:01.430855Z",
     "iopub.status.busy": "2026-02-07T02:56:01.430582Z",
     "iopub.status.idle": "2026-02-07T02:56:01.443568Z",
     "shell.execute_reply": "2026-02-07T02:56:01.443012Z",
     "shell.execute_reply.started": "2026-02-07T02:56:01.430826Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loss functions loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  Nguồn: training/detectors/gend_detector.py (phần loss)\n",
    "# ============================================================\n",
    "\n",
    "def alignment_loss(embeddings, labels, alpha=2):\n",
    "    \"\"\"\n",
    "    Label-aware Alignment loss: Kéo các mẫu cùng nhãn lại gần nhau.\n",
    "    \"\"\"\n",
    "    if embeddings.size(0) < 2:\n",
    "        return torch.tensor(0.0, device=embeddings.device)\n",
    "\n",
    "    labels_equal_mask = (labels[:, None] == labels[None, :]).triu(diagonal=1)\n",
    "    positive_indices = torch.nonzero(labels_equal_mask, as_tuple=False)\n",
    "\n",
    "    if positive_indices.numel() == 0:\n",
    "        return torch.tensor(0.0, device=embeddings.device)\n",
    "\n",
    "    x = embeddings[positive_indices[:, 0]]\n",
    "    y = embeddings[positive_indices[:, 1]]\n",
    "\n",
    "    return (x - y).norm(p=2, dim=1).pow(alpha).mean()\n",
    "\n",
    "\n",
    "def uniformity_loss(x, t=2, clip_value=1e-6):\n",
    "    \"\"\"\n",
    "    Uniformity loss: Đẩy các mẫu phân bố đều trên mặt cầu.\n",
    "    \"\"\"\n",
    "    if x.size(0) < 2:\n",
    "        return torch.tensor(0.0, device=x.device)\n",
    "    return torch.pdist(x, p=2).pow(2).mul(-t).exp().mean().clamp(min=clip_value).log()\n",
    "\n",
    "\n",
    "print(\"\\u2705 Loss functions loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baea5de",
   "metadata": {},
   "source": [
    "## Cell 9 — Model GenD (CLIP ViT-L/14 + LN-Tuning)\n",
    "\n",
    "Sao chép từ `training/detectors/gend_detector.py`.  \n",
    "- Đã bỏ `@DETECTOR.register_module` decorator.  \n",
    "- Đã bỏ `from detectors import DETECTOR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3dad5e60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T02:56:01.446183Z",
     "iopub.status.busy": "2026-02-07T02:56:01.445614Z",
     "iopub.status.idle": "2026-02-07T02:56:01.459441Z",
     "shell.execute_reply": "2026-02-07T02:56:01.458777Z",
     "shell.execute_reply.started": "2026-02-07T02:56:01.446161Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GenDDetector class loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  Nguồn: training/detectors/gend_detector.py\n",
    "#  Đã chỉnh sửa: bỏ DETECTOR registry, inline loss imports\n",
    "# ============================================================\n",
    "\n",
    "class GenDDetector(nn.Module):\n",
    "    def __init__(self, config=None):\n",
    "        super(GenDDetector, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # 1. Load Backbone (CLIP ViT-L/14)\n",
    "        print(\"Loading CLIP ViT-L/14 for GenD...\")\n",
    "        self.backbone = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").vision_model\n",
    "\n",
    "        # 2. Setup LN-Tuning (Chỉ train LayerNorm)\n",
    "        self._setup_training_params()\n",
    "\n",
    "        # 3. Classifier Head\n",
    "        self.head = nn.Linear(1024, 2)\n",
    "\n",
    "        # 4. Loss Weights\n",
    "        self.lambda_align = config.get('lambda_align', 1.0) if config else 1.0\n",
    "        self.lambda_unif = config.get('lambda_unif', 1.0) if config else 1.0\n",
    "\n",
    "        self.loss_ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def _setup_training_params(self):\n",
    "        \"\"\"\n",
    "        Đóng băng toàn bộ backbone, CHỈ mở khóa các lớp LayerNorm.\n",
    "        \"\"\"\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        trainable_params = 0\n",
    "        for name, param in self.backbone.named_parameters():\n",
    "            if 'layer_norm' in name or 'layernorm' in name:\n",
    "                param.requires_grad = True\n",
    "                trainable_params += param.numel()\n",
    "\n",
    "        print(f\"GenD Initialized. Trainable backbone params (LayerNorm): {trainable_params:,}\")\n",
    "        print(f\"Classifier head params: {1024 * 2 + 2:,}\")\n",
    "\n",
    "    def features(self, data_dict: dict) -> torch.Tensor:\n",
    "        outputs = self.backbone(data_dict['image'])\n",
    "        feat = outputs.pooler_output  # [B, 1024]\n",
    "        feat = F.normalize(feat, p=2, dim=1)\n",
    "        return feat\n",
    "\n",
    "    def classifier(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        return self.head(features)\n",
    "\n",
    "    def forward(self, data_dict: dict, inference=False) -> dict:\n",
    "        features = self.features(data_dict)\n",
    "        pred = self.classifier(features)\n",
    "        prob = torch.softmax(pred, dim=1)[:, 1]\n",
    "        return {'cls': pred, 'prob': prob, 'feat': features}\n",
    "\n",
    "    def get_losses(self, data_dict: dict, pred_dict: dict) -> dict:\n",
    "        label = data_dict['label']\n",
    "        pred = pred_dict['cls']\n",
    "        features = pred_dict['feat']\n",
    "\n",
    "        loss_cls = self.loss_ce(pred, label)\n",
    "\n",
    "        loss_align = torch.tensor(0.0, device=pred.device)\n",
    "        loss_unif = torch.tensor(0.0, device=pred.device)\n",
    "\n",
    "        if self.training:\n",
    "            loss_align = alignment_loss(features, label)\n",
    "            loss_unif = uniformity_loss(features)\n",
    "\n",
    "        overall = loss_cls + (self.lambda_align * loss_align) + (self.lambda_unif * loss_unif)\n",
    "\n",
    "        return {\n",
    "            'overall': overall,\n",
    "            'ce_loss': loss_cls,\n",
    "            'align_loss': loss_align,\n",
    "            'unif_loss': loss_unif,\n",
    "        }\n",
    "\n",
    "    def get_train_metrics(self, data_dict: dict, pred_dict: dict) -> dict:\n",
    "        label = data_dict['label']\n",
    "        pred = pred_dict['cls']\n",
    "        auc, eer, acc, ap = calculate_metrics_for_train(label.detach(), pred.detach())\n",
    "        return {'acc': acc, 'auc': auc, 'eer': eer, 'ap': ap}\n",
    "\n",
    "\n",
    "print(\"\\u2705 GenDDetector class loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c764373",
   "metadata": {},
   "source": [
    "## Cell 10 — SAM Optimizer & Scheduler\n",
    "\n",
    "Sao chép từ `training/optimizor/SAM.py` và `training/optimizor/LinearLR.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7cac1074",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T02:56:01.460646Z",
     "iopub.status.busy": "2026-02-07T02:56:01.460370Z",
     "iopub.status.idle": "2026-02-07T02:56:01.477026Z",
     "shell.execute_reply": "2026-02-07T02:56:01.476319Z",
     "shell.execute_reply.started": "2026-02-07T02:56:01.460616Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SAM Optimizer & LinearDecayLR loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  Nguồn: training/optimizor/SAM.py\n",
    "# ============================================================\n",
    "\n",
    "def disable_running_stats(model):\n",
    "    def _disable(module):\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            module.backup_momentum = module.momentum\n",
    "            module.momentum = 0\n",
    "    model.apply(_disable)\n",
    "\n",
    "def enable_running_stats(model):\n",
    "    def _enable(module):\n",
    "        if isinstance(module, nn.BatchNorm2d) and hasattr(module, \"backup_momentum\"):\n",
    "            module.momentum = module.backup_momentum\n",
    "    model.apply(_enable)\n",
    "\n",
    "\n",
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho: {rho}\"\n",
    "        defaults = dict(rho=rho, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                e_w = p.grad * scale.to(p)\n",
    "                p.add_(e_w)\n",
    "                self.state[p][\"e_w\"] = e_w\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.sub_(self.state[p][\"e_w\"])\n",
    "        self.base_optimizer.step()\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"SAM requires closure\"\n",
    "        closure = torch.enable_grad()(closure)\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device\n",
    "        norm = torch.norm(\n",
    "            torch.stack([\n",
    "                p.grad.norm(p=2).to(shared_device)\n",
    "                for group in self.param_groups for p in group[\"params\"]\n",
    "                if p.grad is not None\n",
    "            ]), p=2)\n",
    "        return norm\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#  Nguồn: training/optimizor/LinearLR.py\n",
    "# ============================================================\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "class LinearDecayLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, n_epoch, start_decay, last_epoch=-1):\n",
    "        self.start_decay = start_decay\n",
    "        self.n_epoch = n_epoch\n",
    "        super(LinearDecayLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        last_epoch = self.last_epoch\n",
    "        n_epoch = self.n_epoch\n",
    "        b_lr = self.base_lrs[0]\n",
    "        start_decay = self.start_decay\n",
    "        if last_epoch > start_decay:\n",
    "            lr = b_lr - b_lr / (n_epoch - start_decay) * (last_epoch - start_decay)\n",
    "        else:\n",
    "            lr = b_lr\n",
    "        return [lr]\n",
    "\n",
    "\n",
    "print(\"\\u2705 SAM Optimizer & LinearDecayLR loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb033d3",
   "metadata": {},
   "source": [
    "## Cell 11 — Helper Functions (Optimizer, Scheduler, DataLoader)\n",
    "\n",
    "Sao chép logic từ `training/train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb363e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T02:56:01.478285Z",
     "iopub.status.busy": "2026-02-07T02:56:01.477940Z",
     "iopub.status.idle": "2026-02-07T02:56:01.492682Z",
     "shell.execute_reply": "2026-02-07T02:56:01.491936Z",
     "shell.execute_reply.started": "2026-02-07T02:56:01.478255Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Helper functions loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  Nguồn: training/train.py (các hàm helper)\n",
    "#  FIX: choose_optimizer dùng model.parameters() (giống gốc, không filter),\n",
    "#       prepare_testing_data thêm drop_last cho DeepFakeDetection\n",
    "# ============================================================\n",
    "\n",
    "def choose_optimizer(model, config):\n",
    "    \"\"\"Chọn optimizer — giống hệt train.py gốc (dùng model.parameters() không filter).\"\"\"\n",
    "    opt_name = config['optimizer']['type']\n",
    "\n",
    "    if opt_name == 'sgd':\n",
    "        return optim.SGD(\n",
    "            params=model.parameters(),\n",
    "            lr=config['optimizer'][opt_name]['lr'],\n",
    "            momentum=config['optimizer'][opt_name]['momentum'],\n",
    "            weight_decay=config['optimizer'][opt_name]['weight_decay'],\n",
    "        )\n",
    "    elif opt_name == 'adam':\n",
    "        return optim.Adam(\n",
    "            params=model.parameters(),\n",
    "            lr=config['optimizer'][opt_name]['lr'],\n",
    "            weight_decay=config['optimizer'][opt_name]['weight_decay'],\n",
    "            betas=(config['optimizer'][opt_name]['beta1'], config['optimizer'][opt_name]['beta2']),\n",
    "            eps=config['optimizer'][opt_name]['eps'],\n",
    "            amsgrad=config['optimizer'][opt_name]['amsgrad'],\n",
    "        )\n",
    "    elif opt_name == 'sam':\n",
    "        return SAM(\n",
    "            model.parameters(),\n",
    "            optim.SGD,\n",
    "            lr=config['optimizer'][opt_name]['lr'],\n",
    "            momentum=config['optimizer'][opt_name]['momentum'],\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(f'Optimizer {opt_name} is not implemented')\n",
    "\n",
    "\n",
    "def choose_scheduler(config, optimizer):\n",
    "    \"\"\"Chọn scheduler — giống hệt train.py gốc.\"\"\"\n",
    "    if config['lr_scheduler'] is None:\n",
    "        return None\n",
    "    elif config['lr_scheduler'] == 'step':\n",
    "        return optim.lr_scheduler.StepLR(optimizer, step_size=config['lr_step'], gamma=config['lr_gamma'])\n",
    "    elif config['lr_scheduler'] == 'cosine':\n",
    "        return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['lr_T_max'], eta_min=config['lr_eta_min'])\n",
    "    elif config['lr_scheduler'] == 'linear':\n",
    "        return LinearDecayLR(optimizer, config['nEpochs'], int(config['nEpochs'] / 4))\n",
    "    else:\n",
    "        raise NotImplementedError(f'Scheduler {config[\"lr_scheduler\"]} not implemented')\n",
    "\n",
    "\n",
    "def prepare_training_data(config):\n",
    "    \"\"\"Tạo train DataLoader — giống hệt train.py gốc (branch DeepfakeAbstractBaseDataset).\"\"\"\n",
    "    train_set = DeepfakeAbstractBaseDataset(config=config, mode='train')\n",
    "    train_data_loader = DataLoader(\n",
    "        dataset=train_set,\n",
    "        batch_size=config['train_batchSize'],\n",
    "        shuffle=True,\n",
    "        num_workers=int(config['workers']),\n",
    "        collate_fn=train_set.collate_fn,\n",
    "    )\n",
    "    return train_data_loader\n",
    "\n",
    "\n",
    "def prepare_testing_data(config):\n",
    "    \"\"\"Tạo test DataLoaders — giống hệt train.py gốc (bao gồm drop_last cho DeepFakeDetection).\"\"\"\n",
    "    def get_test_data_loader(config, test_name):\n",
    "        test_cfg = config.copy()\n",
    "        test_cfg['test_dataset'] = test_name\n",
    "        test_set = DeepfakeAbstractBaseDataset(config=test_cfg, mode='test')\n",
    "        test_data_loader = DataLoader(\n",
    "            dataset=test_set,\n",
    "            batch_size=config['test_batchSize'],\n",
    "            shuffle=False,\n",
    "            num_workers=int(config['workers']),\n",
    "            collate_fn=test_set.collate_fn,\n",
    "            drop_last=(test_name == 'DeepFakeDetection'),  # giống gốc\n",
    "        )\n",
    "        return test_data_loader\n",
    "\n",
    "    test_data_loaders = {}\n",
    "    for one_test_name in config['test_dataset']:\n",
    "        test_data_loaders[one_test_name] = get_test_data_loader(config, one_test_name)\n",
    "    return test_data_loaders\n",
    "\n",
    "\n",
    "print(\"\\u2705 Helper functions loaded (matching original project).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca7383f",
   "metadata": {},
   "source": [
    "## Cell 12 — Training Loop & Validation\n",
    "\n",
    "Viết lại từ `training/trainer/trainer.py` — khớp 100% pipeline gốc:\n",
    "- **Log format**: `Iter: {step_cnt}  training-loss, {k}: {v}` (giống gốc, mỗi 300 iteration)\n",
    "- **Mid-epoch testing**: Test 2 lần/epoch (epoch ≥ 1), 1 lần (epoch 0)\n",
    "- **Test logging**: Gồm test loss, test metrics, video_auc, acc_real/acc_fake\n",
    "- **Best metric**: Track per-dataset, save checkpoint per test dataset\n",
    "- **train_step**: Hỗ trợ cả Adam (1-step) và SAM (2-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243991ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T02:56:01.494011Z",
     "iopub.status.busy": "2026-02-07T02:56:01.493782Z",
     "iopub.status.idle": "2026-02-07T02:56:01.512678Z",
     "shell.execute_reply": "2026-02-07T02:56:01.512009Z",
     "shell.execute_reply.started": "2026-02-07T02:56:01.493990Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training loop & validation loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  Training Loop (viết lại từ trainer/trainer.py, khớp 100% pipeline gốc)\n",
    "#  FIX: Log format giống gốc (Iter: step_cnt, training-loss/metric),\n",
    "#       mid-epoch testing, test loss logging, acc_real/acc_fake,\n",
    "#       best metric tracking per dataset, 300-iteration log interval\n",
    "# ============================================================\n",
    "\n",
    "FFpp_pool_ckpt = ['FaceForensics++', 'FF-DF', 'FF-F2F', 'FF-FS', 'FF-NT']\n",
    "\n",
    "\n",
    "def get_respect_acc(prob, label):\n",
    "    \"\"\"Tính accuracy riêng cho real và fake — giống hệt trainer gốc.\"\"\"\n",
    "    pred = np.where(prob > 0.5, 1, 0)\n",
    "    judge = (pred == label)\n",
    "    real_idx = np.where(label == 0)[0]\n",
    "    fake_idx = np.where(label == 1)[0]\n",
    "    acc_real = np.count_nonzero(judge[real_idx]) / len(real_idx) if len(real_idx) > 0 else 0.0\n",
    "    acc_fake = np.count_nonzero(judge[fake_idx]) / len(fake_idx) if len(fake_idx) > 0 else 0.0\n",
    "    return acc_real, acc_fake\n",
    "\n",
    "\n",
    "def train_step(model, data_dict, optimizer, config):\n",
    "    \"\"\"Một bước train — giống hệt trainer.train_step().\"\"\"\n",
    "    if config['optimizer']['type'] == 'sam':\n",
    "        for i in range(2):\n",
    "            predictions = model(data_dict)\n",
    "            losses = model.get_losses(data_dict, predictions)\n",
    "            if i == 0:\n",
    "                pred_first = predictions\n",
    "                losses_first = losses\n",
    "            optimizer.zero_grad()\n",
    "            losses['overall'].backward()\n",
    "            if i == 0:\n",
    "                optimizer.first_step(zero_grad=True)\n",
    "            else:\n",
    "                optimizer.second_step(zero_grad=True)\n",
    "        return losses_first, pred_first\n",
    "    else:\n",
    "        predictions = model(data_dict)\n",
    "        losses = model.get_losses(data_dict, predictions)\n",
    "        optimizer.zero_grad()\n",
    "        losses['overall'].backward()\n",
    "        optimizer.step()\n",
    "        return losses, predictions\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_one_dataset(model, data_loader):\n",
    "    \"\"\"Test 1 dataset — giống hệt trainer.test_one_dataset().\"\"\"\n",
    "    test_recorder_loss = defaultdict(Recorder)\n",
    "    prediction_lists = []\n",
    "    feature_lists = []\n",
    "    label_lists = []\n",
    "\n",
    "    for i, data_dict in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        if data_dict is None:\n",
    "            continue\n",
    "        # Fix label to binary (giống gốc)\n",
    "        if 'label_spe' in data_dict:\n",
    "            data_dict.pop('label_spe')\n",
    "        data_dict['label'] = torch.where(data_dict['label'] != 0, 1, 0)\n",
    "        # Move to GPU\n",
    "        for key in data_dict.keys():\n",
    "            if data_dict[key] is not None and isinstance(data_dict[key], torch.Tensor):\n",
    "                data_dict[key] = data_dict[key].to(device)\n",
    "        # Forward (inference mode)\n",
    "        predictions = model(data_dict, inference=True)\n",
    "        label_lists += list(data_dict['label'].cpu().detach().numpy())\n",
    "        prediction_lists += list(predictions['prob'].cpu().detach().numpy())\n",
    "        feature_lists += list(predictions['feat'].cpu().detach().numpy())\n",
    "        # Compute losses (giống gốc)\n",
    "        losses = model.get_losses(data_dict, predictions)\n",
    "        for name, value in losses.items():\n",
    "            test_recorder_loss[name].update(value)\n",
    "\n",
    "    return test_recorder_loss, np.array(prediction_lists), np.array(label_lists), np.array(feature_lists)\n",
    "\n",
    "\n",
    "def save_best_and_log(logger, epoch, iteration, step_cnt, losses_recorder, key,\n",
    "                      metric_one_dataset, best_metrics_all_time, metric_scoring,\n",
    "                      config, log_dir, model):\n",
    "    \"\"\"\n",
    "    Lưu checkpoint nếu cải thiện + in log — giống hệt trainer.save_best().\n",
    "    In testing-loss và testing-metric với format gốc.\n",
    "    \"\"\"\n",
    "    best_metric = best_metrics_all_time[key].get(\n",
    "        metric_scoring,\n",
    "        float('-inf') if metric_scoring != 'eer' else float('inf')\n",
    "    )\n",
    "    improved = (metric_one_dataset[metric_scoring] > best_metric) if metric_scoring != 'eer' else \\\n",
    "               (metric_one_dataset[metric_scoring] < best_metric)\n",
    "    if improved:\n",
    "        best_metrics_all_time[key][metric_scoring] = metric_one_dataset[metric_scoring]\n",
    "        if key == 'avg':\n",
    "            best_metrics_all_time[key]['dataset_dict'] = metric_one_dataset['dataset_dict']\n",
    "        if config['save_ckpt'] and key not in FFpp_pool_ckpt:\n",
    "            save_checkpoint(model, logger,\n",
    "                            os.path.join(log_dir, 'test', key, 'ckpt_best.pth'),\n",
    "                            info=f\"{epoch}+{iteration}\")\n",
    "\n",
    "    # Log test losses (giống gốc)\n",
    "    if losses_recorder is not None:\n",
    "        loss_str = f\"dataset: {key}    step: {step_cnt}    \"\n",
    "        for k, v in losses_recorder.items():\n",
    "            v_avg = v.average()\n",
    "            if v_avg is None:\n",
    "                print(f'{k} is not calculated')\n",
    "                continue\n",
    "            loss_str += f\"testing-loss, {k}: {v_avg}    \"\n",
    "        logger.info(loss_str)\n",
    "\n",
    "    # Log test metrics (giống gốc: bao gồm video_auc, acc_real, acc_fake)\n",
    "    metric_str = f\"dataset: {key}    step: {step_cnt}    \"\n",
    "    for k, v in metric_one_dataset.items():\n",
    "        if k == 'pred' or k == 'label' or k == 'dataset_dict':\n",
    "            continue\n",
    "        metric_str += f\"testing-metric, {k}: {v}    \"\n",
    "    if 'pred' in metric_one_dataset:\n",
    "        acc_real, acc_fake = get_respect_acc(metric_one_dataset['pred'], metric_one_dataset['label'])\n",
    "        metric_str += f'testing-metric, acc_real:{acc_real}; acc_fake:{acc_fake}'\n",
    "    logger.info(metric_str)\n",
    "\n",
    "\n",
    "def test_epoch(model, test_loaders, logger, epoch, iteration, step_cnt,\n",
    "               config, best_metrics_all_time, metric_scoring, log_dir):\n",
    "    \"\"\"\n",
    "    Test toàn bộ test datasets — giống hệt trainer.test_epoch().\n",
    "    Bao gồm: test loss, test metrics, video_auc, acc_real/acc_fake, best ckpt tracking.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    avg_metric = {'acc': 0, 'auc': 0, 'eer': 0, 'ap': 0, 'video_auc': 0, 'dataset_dict': {}}\n",
    "\n",
    "    for key, loader in test_loaders.items():\n",
    "        # Test one dataset\n",
    "        losses_recorder, predictions_nps, label_nps, feature_nps = test_one_dataset(model, loader)\n",
    "\n",
    "        # Get test metrics (includes video-level AUC)\n",
    "        data_dict = loader.dataset.data_dict\n",
    "        metric_one_dataset = get_test_metrics(\n",
    "            y_pred=predictions_nps, y_true=label_nps, img_names=data_dict['image']\n",
    "        )\n",
    "\n",
    "        # Accumulate for average\n",
    "        for metric_name, value in metric_one_dataset.items():\n",
    "            if metric_name in avg_metric:\n",
    "                avg_metric[metric_name] += value\n",
    "        avg_metric['dataset_dict'][key] = metric_one_dataset[metric_scoring]\n",
    "\n",
    "        # Save best + log (giống gốc)\n",
    "        save_best_and_log(logger, epoch, iteration, step_cnt, losses_recorder, key,\n",
    "                          metric_one_dataset, best_metrics_all_time, metric_scoring,\n",
    "                          config, log_dir, model)\n",
    "\n",
    "        # Save features if configured\n",
    "        if config.get('save_feat', False) and feature_nps is not None:\n",
    "            feat_save_dir = os.path.join(log_dir, 'test', key)\n",
    "            os.makedirs(feat_save_dir, exist_ok=True)\n",
    "            np.save(os.path.join(feat_save_dir, 'feat_best.npy'), feature_nps)\n",
    "            logger.info(f\"Feature saved to {os.path.join(feat_save_dir, 'feat_best.npy')}\")\n",
    "\n",
    "    # Average metrics (giống gốc)\n",
    "    if len(test_loaders) > 0 and config.get('save_avg', False):\n",
    "        for k in avg_metric:\n",
    "            if k != 'dataset_dict':\n",
    "                avg_metric[k] /= len(test_loaders)\n",
    "        save_best_and_log(logger, epoch, iteration, step_cnt, None, 'avg',\n",
    "                          avg_metric, best_metrics_all_time, metric_scoring,\n",
    "                          config, log_dir, model)\n",
    "\n",
    "    logger.info('===> Test Done!')\n",
    "    return best_metrics_all_time\n",
    "\n",
    "\n",
    "def train_one_epoch(model, train_loader, test_loaders, optimizer, config, logger, epoch,\n",
    "                    best_metrics_all_time, metric_scoring, log_dir):\n",
    "    \"\"\"\n",
    "    Train 1 epoch — giống hệt trainer.train_epoch().\n",
    "    Bao gồm:\n",
    "    - Log loss & metric mỗi 300 iterations (format gốc: \"Iter: step_cnt  training-loss, ...\")\n",
    "    - Mid-epoch testing: test 2 lần/epoch khi epoch >= 1, 1 lần khi epoch 0\n",
    "    \"\"\"\n",
    "    logger.info(f\"===> Epoch[{epoch}] start!\")\n",
    "    model.train()\n",
    "\n",
    "    # Giống trainer gốc: test nhiều lần / epoch\n",
    "    times_per_epoch = 2 if epoch >= 1 else 1\n",
    "    test_step = len(train_loader) // times_per_epoch\n",
    "    step_cnt = epoch * len(train_loader)\n",
    "\n",
    "    # Recorders (giống gốc)\n",
    "    train_recorder_loss = defaultdict(Recorder)\n",
    "    train_recorder_metric = defaultdict(Recorder)\n",
    "\n",
    "    test_best_metric = None\n",
    "\n",
    "    for iteration, data_dict in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        model.train()  # Đảm bảo train mode sau mỗi lần test\n",
    "        if data_dict is None:\n",
    "            step_cnt += 1\n",
    "            continue\n",
    "\n",
    "        # Move to GPU (giống gốc)\n",
    "        for key in data_dict.keys():\n",
    "            if data_dict[key] is not None and isinstance(data_dict[key], torch.Tensor):\n",
    "                data_dict[key] = data_dict[key].to(device)\n",
    "\n",
    "        # Train step\n",
    "        losses, predictions = train_step(model, data_dict, optimizer, config)\n",
    "\n",
    "        # Record batch metrics (giống gốc)\n",
    "        batch_metrics = model.get_train_metrics(data_dict, predictions)\n",
    "        for name, value in batch_metrics.items():\n",
    "            train_recorder_metric[name].update(value)\n",
    "        for name, value in losses.items():\n",
    "            train_recorder_loss[name].update(value)\n",
    "\n",
    "        # --- Logging mỗi 300 iterations (giống trainer gốc: iteration % 300 == 0) ---\n",
    "        if iteration % 300 == 0:\n",
    "            # Loss log (format gốc)\n",
    "            loss_str = f\"Iter: {step_cnt}    \"\n",
    "            for k, v in train_recorder_loss.items():\n",
    "                v_avg = v.average()\n",
    "                if v_avg is None:\n",
    "                    loss_str += f\"training-loss, {k}: not calculated\"\n",
    "                    continue\n",
    "                loss_str += f\"training-loss, {k}: {v_avg}    \"\n",
    "            logger.info(loss_str)\n",
    "\n",
    "            # Metric log (format gốc)\n",
    "            metric_str = f\"Iter: {step_cnt}    \"\n",
    "            for k, v in train_recorder_metric.items():\n",
    "                v_avg = v.average()\n",
    "                if v_avg is None:\n",
    "                    metric_str += f\"training-metric, {k}: not calculated    \"\n",
    "                    continue\n",
    "                metric_str += f\"training-metric, {k}: {v_avg}    \"\n",
    "            logger.info(metric_str)\n",
    "\n",
    "            # Clear recorders (giống gốc: chỉ tính 300 samples gần nhất)\n",
    "            for name, recorder in train_recorder_loss.items():\n",
    "                recorder.clear()\n",
    "            for name, recorder in train_recorder_metric.items():\n",
    "                recorder.clear()\n",
    "\n",
    "        # --- Mid-epoch testing (giống trainer gốc) ---\n",
    "        if (step_cnt + 1) % test_step == 0:\n",
    "            if test_loaders is not None and len(test_loaders) > 0:\n",
    "                logger.info(\"===> Test start!\")\n",
    "                test_best_metric = test_epoch(\n",
    "                    model, test_loaders, logger, epoch, iteration, step_cnt,\n",
    "                    config, best_metrics_all_time, metric_scoring, log_dir\n",
    "                )\n",
    "\n",
    "        step_cnt += 1\n",
    "\n",
    "    return test_best_metric\n",
    "\n",
    "\n",
    "def save_checkpoint(model, logger, path, info=\"\"):\n",
    "    \"\"\"Lưu model state dict — giống hệt trainer.save_ckpt().\"\"\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    logger.info(f\"Checkpoint saved to {path}, current ckpt is {info}\")\n",
    "\n",
    "\n",
    "print(\"\\u2705 Training loop & validation loaded (matching original project).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dd3c26",
   "metadata": {},
   "source": [
    "## Cell 13 — Khởi tạo Model + Optimizer + DataLoaders\n",
    "\n",
    "Cell này sẽ:\n",
    "1. Tạo model GenD (tải CLIP weights từ internet)\n",
    "2. Tạo optimizer và scheduler\n",
    "3. Tạo train/test DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4300dc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T03:00:51.747896Z",
     "iopub.status.busy": "2026-02-07T03:00:51.747606Z",
     "iopub.status.idle": "2026-02-07T03:00:52.610922Z",
     "shell.execute_reply": "2026-02-07T03:00:52.609964Z",
     "shell.execute_reply.started": "2026-02-07T03:00:51.747871Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CLIP ViT-L/14 for GenD...\n",
      "GenD Initialized. Trainable backbone params (LayerNorm): 100,352\n",
      "Classifier head params: 2,050\n",
      "[03:00:52] Total parameters:     303,181,826\n",
      "[03:00:52] Trainable parameters: 102,402\n",
      "[03:00:52] Optimizer: adam\n",
      "[03:00:52] Scheduler: None\n",
      "[03:00:52] Preparing training data...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dataset JSON not found: /kaggle/input/deepfakebench/dataset_json/FaceForensics++.json. Error: [Errno 2] No such file or directory: '/kaggle/input/deepfakebench/dataset_json/FaceForensics++.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55/1341696318.py\u001b[0m in \u001b[0;36mcollect_img_and_label_for_one_dataset\u001b[0;34m(self, dataset_name)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0mdataset_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/deepfakebench/dataset_json/FaceForensics++.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55/2425178519.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 3. DataLoaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preparing training data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train samples: {len(train_loader.dataset):,}  |  Batches: {len(train_loader)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_55/1847635860.py\u001b[0m in \u001b[0;36mprepare_training_data\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepfakeAbstractBaseDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     train_loader = DataLoader(\n\u001b[1;32m     53\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_55/1341696318.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, mode)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mimage_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mone_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mtmp_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_img_and_label_for_one_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mimage_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mlabel_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_55/1341696318.py\u001b[0m in \u001b[0;36mcollect_img_and_label_for_one_dataset\u001b[0;34m(self, dataset_name)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mdataset_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Dataset JSON not found: {json_path}. Error: {e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# Xử lý tên dataset gốc (hỗ trợ _c40 variant)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dataset JSON not found: /kaggle/input/deepfakebench/dataset_json/FaceForensics++.json. Error: [Errno 2] No such file or directory: '/kaggle/input/deepfakebench/dataset_json/FaceForensics++.json'"
     ]
    }
   ],
   "source": [
    "# 1. Model\n",
    "model = GenDDetector(config=config)\n",
    "model = model.to(device)\n",
    "\n",
    "# In số params\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "logger.info(f\"Total parameters:     {total_params:,}\")\n",
    "logger.info(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# 2. Optimizer (giống gốc: dùng model.parameters() không filter)\n",
    "optimizer = choose_optimizer(model, config)\n",
    "scheduler = choose_scheduler(config, optimizer)\n",
    "logger.info(f\"Optimizer: {config['optimizer']['type']}\")\n",
    "logger.info(f\"Scheduler: {config['lr_scheduler']}\")\n",
    "\n",
    "# 3. DataLoaders\n",
    "logger.info(\"Preparing training data...\")\n",
    "train_loader = prepare_training_data(config)\n",
    "logger.info(f\"Train samples: {len(train_loader.dataset):,}  |  Batches: {len(train_loader)}\")\n",
    "\n",
    "logger.info(\"Preparing testing data...\")\n",
    "test_loaders = prepare_testing_data(config)\n",
    "for name, loader in test_loaders.items():\n",
    "    logger.info(f\"Test [{name}]: {len(loader.dataset):,} samples  |  {len(loader)} batches\")\n",
    "\n",
    "# 4. Print configuration (giống train.py gốc)\n",
    "logger.info(\"--------------- Configuration ---------------\")\n",
    "params_string = \"Parameters: \\n\"\n",
    "for key, value in config.items():\n",
    "    params_string += f\"{key}: {value}\\n\"\n",
    "logger.info(params_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14630816",
   "metadata": {},
   "source": [
    "## Cell 14 — CHẠY TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2b69d7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-02-07T02:56:02.482818Z",
     "iopub.status.idle": "2026-02-07T02:56:02.483197Z",
     "shell.execute_reply": "2026-02-07T02:56:02.483027Z",
     "shell.execute_reply.started": "2026-02-07T02:56:02.483004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#  Main Training Loop — giống hệt train.py gốc\n",
    "#  FIX: best_metrics_all_time per-dataset, parse_metric_for_print,\n",
    "#       scheduler.step() chỉ 1 lần sau tất cả epochs (giống gốc)\n",
    "# ============================================================\n",
    "\n",
    "best_metrics_all_time = defaultdict(\n",
    "    lambda: defaultdict(lambda: float('-inf') if metric_scoring != 'eer' else float('inf'))\n",
    ")\n",
    "metric_scoring = config['metric_scoring']\n",
    "\n",
    "best_metric = None\n",
    "\n",
    "for epoch in range(config['start_epoch'], config['nEpochs'] + 1):\n",
    "    model.epoch = epoch  # giống gốc: trainer.model.epoch = epoch\n",
    "\n",
    "    # --- Train (bao gồm mid-epoch testing) ---\n",
    "    best_metric = train_one_epoch(\n",
    "        model, train_loader, test_loaders, optimizer, config, logger, epoch,\n",
    "        best_metrics_all_time, metric_scoring, log_dir\n",
    "    )\n",
    "\n",
    "    if best_metric is not None:\n",
    "        logger.info(f\"===> Epoch[{epoch}] end with testing {metric_scoring}: {parse_metric_for_print(best_metric)}!\")\n",
    "\n",
    "    # Save checkpoint mỗi save_epoch\n",
    "    if config['save_ckpt'] and (epoch % config['save_epoch'] == 0):\n",
    "        epoch_ckpt = os.path.join(log_dir, f'ckpt_epoch_{epoch}.pth')\n",
    "        save_checkpoint(model, logger, epoch_ckpt, info=f\"epoch={epoch}\")\n",
    "\n",
    "# Scheduler step (giống gốc: chỉ step 1 lần sau tất cả epochs)\n",
    "if scheduler is not None:\n",
    "    scheduler.step()\n",
    "\n",
    "if best_metric is not None:\n",
    "    logger.info(f\"Stop Training on best Testing metric {parse_metric_for_print(best_metric)}\")\n",
    "\n",
    "logger.info(f\"\\n{'='*60}\")\n",
    "logger.info(f\"\\u2705 Training complete!\")\n",
    "logger.info(f\"Checkpoints saved in: {log_dir}\")\n",
    "logger.info(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ab052",
   "metadata": {},
   "source": [
    "## Cell 15 — Load Checkpoint & Test lại\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa8b8f1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-02-07T02:56:02.484630Z",
     "iopub.status.idle": "2026-02-07T02:56:02.484961Z",
     "shell.execute_reply": "2026-02-07T02:56:02.484852Z",
     "shell.execute_reply.started": "2026-02-07T02:56:02.484828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#  (Tùy chọn) Load checkpoint và test lại\n",
    "# ============================================================\n",
    "\n",
    "# Bỏ comment dòng dưới để chạy:\n",
    "\n",
    "# ckpt_path = os.path.join(log_dir, 'ckpt_best.pth')\n",
    "# state_dict = torch.load(ckpt_path, map_location=device)\n",
    "# model.load_state_dict(state_dict)\n",
    "# logger.info(f\"Loaded checkpoint: {ckpt_path}\")\n",
    "# \n",
    "# test_results = validate(model, test_loaders, logger)\n",
    "# avg_auc = np.mean([r['auc'] for r in test_results.values()])\n",
    "# logger.info(f\"\\u2705 Test AUC (from saved checkpoint): {avg_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53dbd4e-024b-4336-b7fd-5158afed46e9",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 15605687,
     "datasetId": 9407054,
     "sourceId": 14755205,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
